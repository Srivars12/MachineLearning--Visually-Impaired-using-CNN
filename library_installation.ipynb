{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa6c2ee3-0514-4b8e-befb-29d514a26167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.18.0-cp311-cp311-win_amd64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: keras in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.10.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: gTTS in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.5.4)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (11.1.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: rich in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras) (0.14.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gTTS) (8.1.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras) (2.19.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
      "Using cached tensorflow-2.18.0-cp311-cp311-win_amd64.whl (7.5 kB)\n",
      "Downloading opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "   ---------------------------------------- 0.0/39.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/39.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/39.5 MB 1.5 MB/s eta 0:00:26\n",
      "    --------------------------------------- 0.8/39.5 MB 1.5 MB/s eta 0:00:27\n",
      "   - -------------------------------------- 1.0/39.5 MB 1.4 MB/s eta 0:00:28\n",
      "   - -------------------------------------- 1.3/39.5 MB 1.3 MB/s eta 0:00:31\n",
      "   - -------------------------------------- 1.3/39.5 MB 1.3 MB/s eta 0:00:31\n",
      "   - -------------------------------------- 1.6/39.5 MB 1.1 MB/s eta 0:00:34\n",
      "   - -------------------------------------- 1.6/39.5 MB 1.1 MB/s eta 0:00:34\n",
      "   - -------------------------------------- 1.8/39.5 MB 1.0 MB/s eta 0:00:38\n",
      "   -- ------------------------------------- 2.1/39.5 MB 987.1 kB/s eta 0:00:38\n",
      "   -- ------------------------------------- 2.1/39.5 MB 987.1 kB/s eta 0:00:38\n",
      "   -- ------------------------------------- 2.4/39.5 MB 958.9 kB/s eta 0:00:39\n",
      "   -- ------------------------------------- 2.6/39.5 MB 909.9 kB/s eta 0:00:41\n",
      "   -- ------------------------------------- 2.9/39.5 MB 932.2 kB/s eta 0:00:40\n",
      "   -- ------------------------------------- 2.9/39.5 MB 932.2 kB/s eta 0:00:40\n",
      "   --- ------------------------------------ 3.1/39.5 MB 922.7 kB/s eta 0:00:40\n",
      "   --- ------------------------------------ 3.1/39.5 MB 922.7 kB/s eta 0:00:40\n",
      "   --- ------------------------------------ 3.4/39.5 MB 883.1 kB/s eta 0:00:41\n",
      "   --- ------------------------------------ 3.9/39.5 MB 947.1 kB/s eta 0:00:38\n",
      "   ---- ----------------------------------- 4.2/39.5 MB 964.2 kB/s eta 0:00:37\n",
      "   ---- ----------------------------------- 4.2/39.5 MB 964.2 kB/s eta 0:00:37\n",
      "   ---- ----------------------------------- 4.5/39.5 MB 958.7 kB/s eta 0:00:37\n",
      "   ---- ----------------------------------- 4.7/39.5 MB 970.3 kB/s eta 0:00:36\n",
      "   ----- ---------------------------------- 5.0/39.5 MB 961.8 kB/s eta 0:00:36\n",
      "   ----- ---------------------------------- 5.0/39.5 MB 961.8 kB/s eta 0:00:36\n",
      "   ----- ---------------------------------- 5.2/39.5 MB 951.6 kB/s eta 0:00:36\n",
      "   ----- ---------------------------------- 5.2/39.5 MB 951.6 kB/s eta 0:00:36\n",
      "   ----- ---------------------------------- 5.2/39.5 MB 951.6 kB/s eta 0:00:36\n",
      "   ----- ---------------------------------- 5.5/39.5 MB 880.7 kB/s eta 0:00:39\n",
      "   ----- ---------------------------------- 5.5/39.5 MB 880.7 kB/s eta 0:00:39\n",
      "   ----- ---------------------------------- 5.5/39.5 MB 880.7 kB/s eta 0:00:39\n",
      "   ----- ---------------------------------- 5.8/39.5 MB 833.0 kB/s eta 0:00:41\n",
      "   ----- ---------------------------------- 5.8/39.5 MB 833.0 kB/s eta 0:00:41\n",
      "   ------ --------------------------------- 6.0/39.5 MB 813.1 kB/s eta 0:00:42\n",
      "   ------ --------------------------------- 6.0/39.5 MB 813.1 kB/s eta 0:00:42\n",
      "   ------ --------------------------------- 6.3/39.5 MB 809.0 kB/s eta 0:00:42\n",
      "   ------ --------------------------------- 6.6/39.5 MB 815.2 kB/s eta 0:00:41\n",
      "   ------ --------------------------------- 6.6/39.5 MB 815.2 kB/s eta 0:00:41\n",
      "   ------ --------------------------------- 6.8/39.5 MB 808.2 kB/s eta 0:00:41\n",
      "   ------- -------------------------------- 7.1/39.5 MB 821.6 kB/s eta 0:00:40\n",
      "   ------- -------------------------------- 7.3/39.5 MB 834.3 kB/s eta 0:00:39\n",
      "   ------- -------------------------------- 7.6/39.5 MB 840.4 kB/s eta 0:00:38\n",
      "   ------- -------------------------------- 7.6/39.5 MB 840.4 kB/s eta 0:00:38\n",
      "   ------- -------------------------------- 7.9/39.5 MB 826.1 kB/s eta 0:00:39\n",
      "   ------- -------------------------------- 7.9/39.5 MB 826.1 kB/s eta 0:00:39\n",
      "   -------- ------------------------------- 8.1/39.5 MB 819.8 kB/s eta 0:00:39\n",
      "   -------- ------------------------------- 8.1/39.5 MB 819.8 kB/s eta 0:00:39\n",
      "   -------- ------------------------------- 8.4/39.5 MB 811.4 kB/s eta 0:00:39\n",
      "   -------- ------------------------------- 8.4/39.5 MB 811.4 kB/s eta 0:00:39\n",
      "   -------- ------------------------------- 8.4/39.5 MB 811.4 kB/s eta 0:00:39\n",
      "   -------- ------------------------------- 8.7/39.5 MB 790.7 kB/s eta 0:00:39\n",
      "   --------- ------------------------------ 8.9/39.5 MB 788.7 kB/s eta 0:00:39\n",
      "   --------- ------------------------------ 8.9/39.5 MB 788.7 kB/s eta 0:00:39\n",
      "   --------- ------------------------------ 9.2/39.5 MB 789.0 kB/s eta 0:00:39\n",
      "   --------- ------------------------------ 9.4/39.5 MB 786.1 kB/s eta 0:00:39\n",
      "   --------- ------------------------------ 9.4/39.5 MB 786.1 kB/s eta 0:00:39\n",
      "   --------- ------------------------------ 9.7/39.5 MB 792.6 kB/s eta 0:00:38\n",
      "   ---------- ----------------------------- 10.0/39.5 MB 791.8 kB/s eta 0:00:38\n",
      "   ---------- ----------------------------- 10.2/39.5 MB 803.0 kB/s eta 0:00:37\n",
      "   ---------- ----------------------------- 10.5/39.5 MB 810.8 kB/s eta 0:00:36\n",
      "   ---------- ----------------------------- 10.7/39.5 MB 818.4 kB/s eta 0:00:36\n",
      "   ----------- ---------------------------- 11.0/39.5 MB 821.8 kB/s eta 0:00:35\n",
      "   ----------- ---------------------------- 11.3/39.5 MB 821.3 kB/s eta 0:00:35\n",
      "   ----------- ---------------------------- 11.3/39.5 MB 821.3 kB/s eta 0:00:35\n",
      "   ----------- ---------------------------- 11.3/39.5 MB 821.3 kB/s eta 0:00:35\n",
      "   ----------- ---------------------------- 11.3/39.5 MB 821.3 kB/s eta 0:00:35\n",
      "   ----------- ---------------------------- 11.5/39.5 MB 787.6 kB/s eta 0:00:36\n",
      "   ----------- ---------------------------- 11.5/39.5 MB 787.6 kB/s eta 0:00:36\n",
      "   ----------- ---------------------------- 11.8/39.5 MB 782.8 kB/s eta 0:00:36\n",
      "   ----------- ---------------------------- 11.8/39.5 MB 782.8 kB/s eta 0:00:36\n",
      "   ------------ --------------------------- 12.1/39.5 MB 779.9 kB/s eta 0:00:36\n",
      "   ------------ --------------------------- 12.1/39.5 MB 779.9 kB/s eta 0:00:36\n",
      "   ------------ --------------------------- 12.3/39.5 MB 782.0 kB/s eta 0:00:35\n",
      "   ------------ --------------------------- 12.6/39.5 MB 777.7 kB/s eta 0:00:35\n",
      "   ------------- -------------------------- 12.8/39.5 MB 784.9 kB/s eta 0:00:34\n",
      "   ------------- -------------------------- 13.1/39.5 MB 795.1 kB/s eta 0:00:34\n",
      "   ------------- -------------------------- 13.4/39.5 MB 798.9 kB/s eta 0:00:33\n",
      "   ------------- -------------------------- 13.6/39.5 MB 802.0 kB/s eta 0:00:33\n",
      "   -------------- ------------------------- 13.9/39.5 MB 807.1 kB/s eta 0:00:32\n",
      "   -------------- ------------------------- 14.2/39.5 MB 815.8 kB/s eta 0:00:32\n",
      "   -------------- ------------------------- 14.4/39.5 MB 822.9 kB/s eta 0:00:31\n",
      "   -------------- ------------------------- 14.7/39.5 MB 823.9 kB/s eta 0:00:31\n",
      "   --------------- ------------------------ 14.9/39.5 MB 829.2 kB/s eta 0:00:30\n",
      "   --------------- ------------------------ 15.2/39.5 MB 837.4 kB/s eta 0:00:29\n",
      "   --------------- ------------------------ 15.7/39.5 MB 851.2 kB/s eta 0:00:28\n",
      "   ---------------- ----------------------- 16.0/39.5 MB 858.9 kB/s eta 0:00:28\n",
      "   ---------------- ----------------------- 16.5/39.5 MB 876.4 kB/s eta 0:00:27\n",
      "   ----------------- ---------------------- 17.0/39.5 MB 896.3 kB/s eta 0:00:26\n",
      "   ----------------- ---------------------- 17.6/39.5 MB 909.1 kB/s eta 0:00:25\n",
      "   ------------------ --------------------- 18.1/39.5 MB 926.8 kB/s eta 0:00:24\n",
      "   ------------------- -------------------- 18.9/39.5 MB 955.3 kB/s eta 0:00:22\n",
      "   ------------------- -------------------- 18.9/39.5 MB 955.3 kB/s eta 0:00:22\n",
      "   ------------------- -------------------- 19.1/39.5 MB 955.7 kB/s eta 0:00:22\n",
      "   ------------------- -------------------- 19.1/39.5 MB 955.7 kB/s eta 0:00:22\n",
      "   ------------------- -------------------- 19.1/39.5 MB 955.7 kB/s eta 0:00:22\n",
      "   ------------------- -------------------- 19.1/39.5 MB 955.7 kB/s eta 0:00:22\n",
      "   ------------------- -------------------- 19.1/39.5 MB 955.7 kB/s eta 0:00:22\n",
      "   -------------------- ------------------- 20.7/39.5 MB 973.7 kB/s eta 0:00:20\n",
      "   --------------------- ------------------ 21.0/39.5 MB 981.1 kB/s eta 0:00:19\n",
      "   --------------------- ------------------ 21.2/39.5 MB 981.9 kB/s eta 0:00:19\n",
      "   --------------------- ------------------ 21.5/39.5 MB 983.4 kB/s eta 0:00:19\n",
      "   --------------------- ------------------ 21.5/39.5 MB 983.4 kB/s eta 0:00:19\n",
      "   --------------------- ------------------ 21.5/39.5 MB 983.4 kB/s eta 0:00:19\n",
      "   --------------------- ------------------ 21.5/39.5 MB 983.4 kB/s eta 0:00:19\n",
      "   --------------------- ------------------ 21.5/39.5 MB 983.4 kB/s eta 0:00:19\n",
      "   ---------------------- ----------------- 22.5/39.5 MB 980.1 kB/s eta 0:00:18\n",
      "   ----------------------- ---------------- 22.8/39.5 MB 990.3 kB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 23.1/39.5 MB 986.2 kB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 23.6/39.5 MB 1.0 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 23.6/39.5 MB 1.0 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 23.9/39.5 MB 993.4 kB/s eta 0:00:16\n",
      "   ------------------------ --------------- 24.4/39.5 MB 1.0 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 24.6/39.5 MB 1.0 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 25.2/39.5 MB 1.0 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 25.4/39.5 MB 1.0 MB/s eta 0:00:14\n",
      "   ------------------------- -------------- 25.4/39.5 MB 1.0 MB/s eta 0:00:14\n",
      "   ------------------------- -------------- 25.4/39.5 MB 1.0 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 25.7/39.5 MB 1.0 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 25.7/39.5 MB 1.0 MB/s eta 0:00:14\n",
      "   --------------------------- ------------ 26.7/39.5 MB 1.0 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 27.3/39.5 MB 1.0 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 27.5/39.5 MB 1.0 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 27.8/39.5 MB 1.0 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 27.8/39.5 MB 1.0 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 27.8/39.5 MB 1.0 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 27.8/39.5 MB 1.0 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 27.8/39.5 MB 1.0 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 28.3/39.5 MB 1.0 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 28.8/39.5 MB 1.0 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 28.8/39.5 MB 1.0 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 29.1/39.5 MB 1.0 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 29.4/39.5 MB 1.0 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 29.6/39.5 MB 1.0 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 29.9/39.5 MB 1.0 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 30.1/39.5 MB 1.0 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 30.4/39.5 MB 1.0 MB/s eta 0:00:09\n",
      "   ------------------------------ --------- 30.4/39.5 MB 1.0 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 30.9/39.5 MB 1.0 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 31.2/39.5 MB 1.0 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 31.5/39.5 MB 1.0 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 31.7/39.5 MB 1.0 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 32.2/39.5 MB 1.0 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 32.2/39.5 MB 1.0 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 32.5/39.5 MB 1.0 MB/s eta 0:00:07\n",
      "   -------------------------------- ------- 32.5/39.5 MB 1.0 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 32.8/39.5 MB 1.0 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 33.0/39.5 MB 1.0 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 33.0/39.5 MB 1.0 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 33.3/39.5 MB 1.0 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 33.3/39.5 MB 1.0 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 33.6/39.5 MB 1.0 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 33.8/39.5 MB 1.0 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 33.8/39.5 MB 1.0 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 34.1/39.5 MB 1.0 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 34.1/39.5 MB 1.0 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 34.3/39.5 MB 1.0 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 34.9/39.5 MB 1.0 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 35.1/39.5 MB 1.0 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 35.4/39.5 MB 1.0 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 35.7/39.5 MB 1.0 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 35.9/39.5 MB 1.0 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 36.2/39.5 MB 1.0 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 36.7/39.5 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 36.7/39.5 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 37.0/39.5 MB 1.1 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 37.2/39.5 MB 1.1 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 38.0/39.5 MB 1.1 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 38.3/39.5 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------------------------------------  38.8/39.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.1/39.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  39.3/39.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 39.5/39.5 MB 1.1 MB/s eta 0:00:00\n",
      "Installing collected packages: opencv-python, tensorflow\n",
      "Successfully installed opencv-python-4.11.0.86 tensorflow-2.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow keras numpy pandas matplotlib tqdm gTTS opencv-python pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1409d38-d5c1-47f1-932c-12d51151c933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images Folder Exists: True\n",
      "Annotations File Exists: True\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = r\"G:\\coco-2017\\coco2017\\train2017\"\n",
    "ANNOTATIONS_FILE = r\"G:\\coco-2017\\coco2017\\annotations\\captions_train2017.json\"\n",
    "\n",
    "# Check if paths exist\n",
    "print(\"Train Images Folder Exists:\", os.path.exists(DATASET_PATH))\n",
    "print(\"Annotations File Exists:\", os.path.exists(ANNOTATIONS_FILE))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24cf4e8e-919f-4478-b219-a3b8af571752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Images with Captions: 118287\n"
     ]
    }
   ],
   "source": [
    "with open(ANNOTATIONS_FILE, 'r') as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "# Create a dictionary to map images to their captions\n",
    "image_captions = {}\n",
    "for annot in annotations['annotations']:\n",
    "    image_id = annot['image_id']\n",
    "    image_filename = f\"{image_id:012d}.jpg\"\n",
    "    caption = annot['caption']\n",
    "\n",
    "    if image_filename not in image_captions:\n",
    "        image_captions[image_filename] = []\n",
    "    image_captions[image_filename].append(caption)\n",
    "\n",
    "print(\"Total Images with Captions:\", len(image_captions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c53dfff2-499c-4fc9-8d75-8ebf7200d676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images Folder Exists: True\n",
      "Annotations File Exists: True\n",
      "Total annotations: 591753\n",
      "Sample annotation: {'image_id': 203564, 'id': 37, 'caption': 'A bicycle replica with a clock as the front wheel.'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Define dataset paths\n",
    "DATASET_PATH = r\"G:\\coco-2017\\coco2017\\train2017\"\n",
    "ANNOTATIONS_FILE = r\"G:\\coco-2017\\coco2017\\annotations\\captions_train2017.json\"\n",
    "\n",
    "# Check if paths exist\n",
    "print(\"Train Images Folder Exists:\", os.path.exists(DATASET_PATH))\n",
    "print(\"Annotations File Exists:\", os.path.exists(ANNOTATIONS_FILE))\n",
    "\n",
    "# Load annotations\n",
    "with open(ANNOTATIONS_FILE, 'r') as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "# Check sample annotations\n",
    "print(\"Total annotations:\", len(annotations['annotations']))\n",
    "print(\"Sample annotation:\", annotations['annotations'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3670928-ac31-40a1-a622-a283ca4e0171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captions cleaned and saved!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from pickle import dump\n",
    "\n",
    "# Dictionary to store image-caption mappings\n",
    "image_captions = {}\n",
    "\n",
    "for annot in annotations['annotations']:\n",
    "    image_id = annot['image_id']\n",
    "    image_filename = f\"{image_id:012d}.jpg\"\n",
    "    caption = annot['caption']\n",
    "\n",
    "    # Clean text (lowercase, remove punctuation)\n",
    "    caption = caption.lower().translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "    if image_filename not in image_captions:\n",
    "        image_captions[image_filename] = []\n",
    "    image_captions[image_filename].append(caption)\n",
    "\n",
    "# Save cleaned captions\n",
    "dump(image_captions, open(\"captions.pkl\", \"wb\"))\n",
    "print(\"Captions cleaned and saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d818ace2-15ec-489b-b254-df9ca468ec0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageCaptioningModel(\n",
      "  (embedding): Embedding(5000, 256)\n",
      "  (lstm): LSTM(256, 512, batch_first=True)\n",
      "  (fc): Linear(in_features=512, out_features=5000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ImageCaptioningModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size=256, hidden_size=512):\n",
    "        super(ImageCaptioningModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, features, captions):\n",
    "        captions = self.embedding(captions)\n",
    "        lstm_input = torch.cat((features.unsqueeze(1), captions), dim=1)\n",
    "        output, _ = self.lstm(lstm_input)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "# Example Model Initialization\n",
    "vocab_size = 5000  # Adjust as needed\n",
    "model = ImageCaptioningModel(vocab_size)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bcc7e1d-432e-48f7-a0ca-b80828aeeb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5]\n",
      "Epoch [2/5]\n",
      "Epoch [3/5]\n",
      "Epoch [4/5]\n",
      "Epoch [5/5]\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Example Training Loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Example inputs\n",
    "    sample_features = torch.randn(32, 512)  # Replace with real feature vectors\n",
    "    sample_captions = torch.randint(0, vocab_size, (32, 20))  # Random captions\n",
    "\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2818be2-ef3e-49de-9379-8dc6ea856c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Version: 2.6.0+cpu\n",
      "Torchvision Version: 0.21.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "print(\"Torch Version:\", torch.__version__)\n",
    "print(\"Torchvision Version:\", torchvision.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "334bfb27-a50f-456c-9756-a2faa528802c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA Available: False\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "print(\"Is CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"Device:\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ede472ac-51be-43bf-b9ae-007cd1b2023b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = r\"G:\\coco-2017\\coco2017\\train2017\\000000040204.jpg\"  # Use an actual image file\n",
    "\n",
    "from PIL import Image\n",
    "image = Image.open(image_path)\n",
    "image.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89b297a6-6266-499f-9e67-44b618032da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Load EfficientNet model (pretrained on ImageNet)\n",
    "model = models.efficientnet_b0(pretrained=True)\n",
    "model = torch.nn.Sequential(*list(model.children())[:-1])  # Remove last classification layer\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),  # Resize like Xception\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "123c8c63-89ae-4308-8786-c010b091d48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Vector Shape: (1280,)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def extract_features(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")  # Ensure RGB format\n",
    "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    with torch.no_grad():\n",
    "        features = model(image)\n",
    "    return features.squeeze().numpy()  # Convert to NumPy array\n",
    "\n",
    "# Extract features for your image\n",
    "features = extract_features(image_path)\n",
    "print(\"Feature Vector Shape:\", features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d60c080-69b5-44ba-b411-4a337cc893f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_id': 203564, 'id': 37, 'caption': 'A bicycle replica with a clock as the front wheel.'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "ANNOTATIONS_FILE = r\"G:\\coco-2017\\coco2017\\annotations\\captions_train2017.json\"\n",
    "\n",
    "# Load captions\n",
    "with open(ANNOTATIONS_FILE, 'r') as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "# Print first annotation\n",
    "print(annotations[\"annotations\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a466552b-9748-4411-9410-8c54d88adfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captions for this image: ['a red and white plane is taking off ', 'A airplane that is flying in the sky.', 'A passenger airplane flies low to the ground.', 'A large plane taking off from a runway.', 'An airplane just taking off from the airport']\n"
     ]
    }
   ],
   "source": [
    "# Convert image filename to image_id\n",
    "image_id = int(image_path.split(\"\\\\\")[-1].split(\".\")[0])  # Extract image ID from filename\n",
    "\n",
    "# Get all captions for this image\n",
    "image_captions = [annot[\"caption\"] for annot in annotations[\"annotations\"] if annot[\"image_id\"] == image_id]\n",
    "\n",
    "print(\"Captions for this image:\", image_captions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33e34a70-566f-4eca-9cd6-4749a9a65459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImageCaptioningModel(\n",
      "  (embedding): Embedding(5000, 256)\n",
      "  (lstm): LSTM(256, 512, batch_first=True)\n",
      "  (fc): Linear(in_features=512, out_features=5000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ImageCaptioningModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size=256, hidden_size=512):\n",
    "        super(ImageCaptioningModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, features, captions):\n",
    "        captions = self.embedding(captions)\n",
    "        lstm_input = torch.cat((features.unsqueeze(1), captions), dim=1)\n",
    "        output, _ = self.lstm(lstm_input)\n",
    "        output = self.fc(output)\n",
    "        return output\n",
    "\n",
    "# Example Model Initialization\n",
    "vocab_size = 5000  # Adjust based on tokenizer\n",
    "model = ImageCaptioningModel(vocab_size)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8dc3b861-88b4-4a48-a80d-e332aa23309b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Set the correct model path\n",
    "model_path = r\"G:\\image_generation_caption.pth\"  # Use the correct filename\n",
    "\n",
    "# Load the trained model\n",
    "model = ImageCaptioningModel(vocab_size=5000)  # Ensure the vocab size matches your training\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d69c58b6-90b2-4ff5-9690-e9260fc13c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import EfficientNet_B0_Weights\n",
    "\n",
    "# Load EfficientNet for feature extraction (Updated method)\n",
    "cnn_model = models.efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "cnn_model = torch.nn.Sequential(*list(cnn_model.children())[:-1])  # Remove classification layer\n",
    "cnn_model.eval()  # Set to evaluation mode\n",
    "\n",
    "# Define image transformation pipeline\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Function to extract image features\n",
    "def extract_features(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")  # Ensure RGB format\n",
    "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    with torch.no_grad():\n",
    "        features = cnn_model(image)\n",
    "    return features.squeeze().detach()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d743b05d-7c50-446f-a5eb-0663b1884ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer exists: True\n",
      "Files in G:\\ ['$RECYCLE.BIN', '.ipynb_checkpoints', 'captions.pkl', 'coco-2017', 'coco-2017.zip', 'image_caption.ipynb', 'image_generation_caption.pth', 'image_open.ipynb', 'image_voice.ipynb', 'ml_dataset.csv', 'System Volume Information', 'tokenizer.pkl', 'Untitled.ipynb', 'uploading_dataset.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check if tokenizer.pkl exists\n",
    "tokenizer_path = r\"G:\\tokenizer.pkl\"\n",
    "print(\"Tokenizer exists:\", os.path.exists(tokenizer_path))\n",
    "\n",
    "# List all files in G:\\\n",
    "print(\"Files in G:\\\\\", os.listdir(\"G:\\\\\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "517382df-7cb1-4120-b623-87ea18687498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tokenizer saved successfully at G:\\tokenizer.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Download required dataset for tokenization\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Sample dataset\n",
    "training_captions = [\n",
    "    \"a man is surfing on a big wave\",\n",
    "    \"a dog is playing in the park\",\n",
    "    \"a group of people are riding bicycles\"\n",
    "]\n",
    "\n",
    "# Tokenize each caption\n",
    "tokenized_captions = [word_tokenize(sentence.lower()) for sentence in training_captions]\n",
    "\n",
    "# Build vocabulary\n",
    "word_to_index = {\"<pad>\": 0, \"<start>\": 1, \"<end>\": 2, \"<unk>\": 3}  # Special tokens\n",
    "for caption in tokenized_captions:\n",
    "    for word in caption:\n",
    "        if word not in word_to_index:\n",
    "            word_to_index[word] = len(word_to_index)\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer_path = r\"G:\\tokenizer.pkl\"\n",
    "with open(tokenizer_path, \"wb\") as f:\n",
    "    pickle.dump(word_to_index, f)\n",
    "\n",
    "print(f\"✅ Tokenizer saved successfully at {tokenizer_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bcc8addf-7b5e-4832-81d2-34539e7a186e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tokenizer loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Correct tokenizer path\n",
    "tokenizer_path = r\"G:\\tokenizer.pkl\"\n",
    "\n",
    "# Load the tokenizer\n",
    "with open(tokenizer_path, \"rb\") as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "print(\"✅ Tokenizer loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "694bdf61-40dc-420b-83c3-2f20a165e9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Captions: [['a', 'man', 'is', 'surfing', 'on', 'a', 'big', 'wave'], ['a', 'dog', 'is', 'playing', 'in', 'the', 'park'], ['a', 'group', 'of', 'people', 'are', 'riding', 'bicycles']]\n"
     ]
    }
   ],
   "source": [
    "def simple_tokenizer(text):\n",
    "    return text.lower().split()  # Simple split by spaces\n",
    "\n",
    "# Example\n",
    "training_captions = [\n",
    "    \"A man is surfing on a big wave\",\n",
    "    \"A dog is playing in the park\",\n",
    "    \"A group of people are riding bicycles\"\n",
    "]\n",
    "\n",
    "tokenized_captions = [simple_tokenizer(sentence) for sentence in training_captions]\n",
    "\n",
    "print(\"Tokenized Captions:\", tokenized_captions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2bbc89-0ed9-4d3a-9108-fc02e66f40c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
